# asahi-ane-llm

Utilities that help convert and upload ONNX language models to the Asahi ANE
(Apple Neural Engine) driver. The helpers wrap the low level DRM ioctls that the
kernel exposes and make it easier to integrate model metadata, buffer
allocation, and submission logic in Python tooling.

## Installing

The package is published as a local helper inside this repository. You can
install it directly from the repository root using `pip` and the [`pyproject.toml`](pyproject.toml).

```bash
pip install -e libs/asahi_ane_llm
```

Optionally install the chat extras when you want to run the TinyLlama demo or
build your own text generation tooling:

```bash
pip install -e libs/asahi_ane_llm[chat]
```

Both commands install the package in editable mode so that local changes in the
repository are picked up immediately. If you publish the package to an index
such as PyPI you can omit `-e` and install directly from the uploaded wheel.

## Usage overview

The helper exposes three primary concepts:

1. `ANEDevice` handles the lifetime of the `/dev/dri/renderD*` file descriptor
   and provides convenience methods to allocate buffers managed by the driver.
2. `AneModelMetadata` parses the embedded `ane.*` metadata that the Asahi tools
   inject in ONNX models generated by the kernel builder pipeline.
3. `submit_onnx_model` uploads the ONNX payload, zeroes tile descriptors, and
   finally executes the `DRM_IOCTL_ANE_SUBMIT` call with the `ANE_SUBMIT_FLAG_ONNX`
   flag.

Refer to [`examples/onnx_submit.py`](../../examples/onnx_submit.py) for a minimal
script and [`examples/tinyllama_chat.py`](../../examples/tinyllama_chat.py) for a
conversational demo built on top of these primitives.
