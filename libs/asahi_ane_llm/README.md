# asahi-ane-llm

Utilities that help convert and upload ONNX language models to the Asahi ANE
(Apple Neural Engine) driver. The helpers wrap the low level DRM ioctls that the
kernel exposes and make it easier to integrate model metadata, buffer
allocation, and submission logic in Python tooling.

## Installing

The package is published as a local helper inside this repository. You can
install it directly from the repository root using `pip` and the [`pyproject.toml`](pyproject.toml).

```bash
pip install -e libs/asahi_ane_llm
```

Optionally install the chat extras when you want to run the TinyLlama demo or
build your own text generation tooling:

```bash
pip install -e libs/asahi_ane_llm[chat]
```

Both commands install the package in editable mode so that local changes in the
repository are picked up immediately. If you publish the package to an index
such as PyPI you can omit `-e` and install directly from the uploaded wheel.

## Usage overview

The helper exposes three primary concepts:

1. `ANEDevice` handles the lifetime of the `/dev/dri/renderD*` file descriptor
   and provides convenience methods to allocate buffers managed by the driver.
2. `AneModelMetadata` parses the embedded `ane.*` metadata that the Asahi tools
   inject in ONNX models generated by the kernel builder pipeline.
3. `submit_onnx_model` uploads the ONNX payload, zeroes tile descriptors, and
   finally executes the `DRM_IOCTL_ANE_SUBMIT` call with the `ANE_SUBMIT_FLAG_ONNX`
   flag.

Refer to [`examples/onnx_submit.py`](../../examples/onnx_submit.py) for a minimal
script and [`examples/tinyllama_chat.py`](../../examples/tinyllama_chat.py) for a
conversational demo built on top of these primitives.

## Converting ONNX models for the ANE

Most upstream ONNX exports do not include the Asahi specific metadata fields
that bundle the compiled ANE microcode and tile descriptor information. Use the
conversion helper to attach these artefacts before uploading the model:

```bash
python3 tools/convert_to_ane.py \
    path/to/model.onnx \
    --bundle path/to/export/bundle.json
```

The helper expects metadata generated by the ANE toolchain. A bundle is a JSON
document containing base64 encoded microcode and (optionally) tile descriptors
and weights. When the tile descriptor payload is included the helper infers the
descriptor size and count automatically. Explicit values can be provided when
the compiler emitted them separately:

```bash
python3 tools/convert_to_ane.py \
    path/to/model.onnx \
    --microcode path/to/model.tsk \
    --tile-descriptors path/to/td.bin \
    --td-count 1024
```

The command derives the missing tile descriptor parameter whenever possible. If
`--tile-descriptors` is present the helper uses the payload length together with
`--td-size` or `--td-count` to infer the remaining value. Optional ANE weight
blobs can be embedded with `--weights`. The tool validates the output by
parsing it with `parse_ane_metadata` and writes the resulting `<model>_ane.onnx`
file next to the original payload unless an explicit `--output` path is
supplied.

### Auto-detecting compiler outputs

When the ANE toolchain emits multiple artefacts inside a build directory it can
be cumbersome to pass every path manually. Point `--artifact-root` at the
compiler output directory and the helper scans it recursively for likely
microcode (`*.tsk`, `*.microcode`), tile descriptor (`*tile_desc*.bin`,
`*.td.bin`) and weight payloads. Any item that is not specified explicitly via
`--microcode`, `--tile-descriptors`, or `--weights` is auto-filled from the
directory contents as long as the scan finds a single unambiguous match.

```bash
python3 tools/convert_to_ane.py \
    path/to/model.onnx \
    --artifact-root build/ane_export
```

The helper prints the artefacts it discovered before embedding them so you can
double-check the selection.

### Assembling ANE microcode from JSON specs

Reverse engineering the ANE instruction set is an ongoing effort. To make the
process less painful the repository ships a standalone assembler that consumes
JSON descriptions derived from projects such as
[`eiln/ane`](https://github.com/eiln/ane). Feed the schema and program
descriptions into `tools/build_microcode.py` to generate the microcode, tile
descriptor table, and optional weights:

```bash
python3 tools/build_microcode.py \
    schema.json \
    program.json \
    --tile-spec tile_desc.json \
    --weights-spec weights.json \
    --output-dir export/
```

* `schema.json` describes the opcode layout (word size, opcode field position,
  per-instruction field shifts, and defaults).
* `program.json` is an array where each element defines an instruction using the
  names from the schema. Every entry supports an optional `repeat` property to
  emit the same word multiple times.
* `tile_desc.json` can either provide a base64-encoded payload or list the
  entries individually. The helper infers the tile descriptor size/count when
  possible.
* `weights.json` accepts either `data_b64` or a numeric list together with the
  word size/endian information.

All JSON documents use standard base64 with URL-safe `-`/`_` characters. Refer
to the docstrings in `asahi_ane_llm.microcode.schema` and
`asahi_ane_llm.microcode.builder` for the full specification. The assembler also
produces `.tsk`, tile descriptor, and weight files inside `--output-dir` so you
can inspect the generated artefacts before embedding them.

`tools/convert_to_ane.py` integrates with the assembler directly. Instead of
pointing at prebuilt binaries you can provide the JSON specs and let the helper
compile everything in one go:

```bash
python3 tools/convert_to_ane.py \
    path/to/model.onnx \
    --ane-schema schema.json \
    --ane-program program.json \
    --ane-tile-spec tile_desc.json \
    --ane-weights-spec weights.json \
    --ane-output-dir export/
```

The converter still accepts manual overrides via `--td-size` and `--td-count`
when the tile descriptor spec omits them. If you already have the compiled
artefacts you can continue using `--microcode`/`--artifact-root` as before.

For a streamlined workflow, `tools/convert_to_apple_npu.py` exposes only the
JSON-driven options and assembles plus embeds the artefacts in a single
command:

```bash
python3 tools/convert_to_apple_npu.py \
    path/to/model.onnx \
    --ane-schema schema.json \
    --ane-program program.json \
    --ane-tile-spec tile_desc.json \
    --ane-weights-spec weights.json \
    --ane-output-dir export/
```

Supply `--td-size` and `--td-count` when the tile spec omits size/count fields
and the helper will reuse the assembled microcode while applying the explicit
dimensions.
